{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from Hugging Face\n",
    "https://huggingface.co/datasets/matsuxr/JaGovFaqs-22k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_ndjson('hf://datasets/matsuxr/JaGovFaqs-22k/data.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DataFrameのメモリ使用量: {df.estimated_size() / (1024 ** 2):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    (\"question : \" + pl.col(\"Question\") + \" | \" + \"answer : \" + pl.col(\"Answer\")).alias(\"combined\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "client = OpenAI()\n",
    "# model = \"text-embedding-3-small\"\n",
    "model = \"pkshatech/GLuCoSE-base-ja\"\n",
    "\n",
    "if model == \"text-embedding-3-small\":\n",
    "    # 48分かかる\n",
    "    def get_embedding(text, model=\"text-embedding-3-small\") -> list[float]:\n",
    "        return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"combined\").map_elements(lambda x: get_embedding(x, model)).alias(\"ada_embedding\")\n",
    "    )\n",
    "    df.write_csv('/app/output/embedded_faq.csv')\n",
    "\n",
    "if model == \"pkshatech/GLuCoSE-base-ja\":\n",
    "    model = SentenceTransformer('pkshatech/GLuCoSE-base-ja')\n",
    "    df[\"ada_embedding\"] = model.encode(df[\"combined\"].to_list(), show_progress_bar=True)\n",
    "    df.write_csv('/app/output/embedded_faq_GLuCoSE-base-ja.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_parquet('/app/output/embedded_faq.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "embeded_df = pl.read_parquet('/app/output/embedded_faq.parquet')\n",
    "embeded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_df[\"ada_embedding\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Qdrant Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(url=\"http://qdrant:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"kankocho_faq\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "from tqdm import tqdm\n",
    "\n",
    "points = embeded_df.iter_rows(named=True)\n",
    "point_structs = [\n",
    "    PointStruct(id=i, vector=row[\"ada_embedding\"], payload={\n",
    "        \"question\": row[\"Question\"],\n",
    "        \"answer\": row[\"Answer\"],\n",
    "        \"copyright\": row[\"copyright\"],\n",
    "        \"url\": row[\"url\"],\n",
    "        \"combined\": row[\"combined\"],\n",
    "    })\n",
    "    for i, row in tqdm(enumerate(points))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_size = 100\n",
    "for chunk in tqdm(point_structs[i:i + chunk_size] for i in range(0, len(point_structs), chunk_size)):\n",
    "    operation_info = client.upsert(\n",
    "        collection_name=\"kankocho_faq\",\n",
    "        wait=True,\n",
    "        points=chunk,\n",
    "    )\n",
    "\n",
    "print(operation_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve related documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "import polars as pl\n",
    "\n",
    "# input = \"商品を販売する時に注意するべきことは何ですか\"\n",
    "# input = \"インサイダー取引について教えてください\"\n",
    "# input = \"相続について教えてください\"\n",
    "input = \"マイナンバーについて教えてください\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "input_embedding = get_embedding(input)\n",
    "\n",
    "\n",
    "qdrant_client = QdrantClient(url=\"http://qdrant:6333\")\n",
    "\n",
    "search_results = qdrant_client.search(\n",
    "    collection_name=\"kankocho_faq\",\n",
    "    query_vector=input_embedding,\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "print(search_results)\n",
    "\n",
    "# 検索結果をPolars DataFrameに変換する関数\n",
    "def search_results_to_dataframe(results):\n",
    "    data = []\n",
    "    for result in results:\n",
    "        payload = result.payload\n",
    "        data.append({\n",
    "            \"id\": result.id,\n",
    "            \"score\": result.score,\n",
    "            \"question\": payload.get(\"question\", \"\"),\n",
    "            \"answer\": payload.get(\"answer\", \"\"),\n",
    "            \"copyright\": payload.get(\"copyright\", \"\"),\n",
    "            \"url\": payload.get(\"url\", \"\"),\n",
    "            \"combined\": payload.get(\"combined\", \"\")\n",
    "        })\n",
    "    return pl.DataFrame(data)\n",
    "\n",
    "# 検索結果をDataFrameに変換\n",
    "df_results = search_results_to_dataframe(search_results)\n",
    "\n",
    "# DataFrameを表示\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"以下の検索結果を引用して、'{input}'に対する回答を生成してください。回答には必ず引用した文章を明示してください。\\n\\n検索結果:\\n{df_results['combined'].to_list()}\"}\n",
    "    ],\n",
    "    #max_tokens=150,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(response)\n",
    "answer = response.choices[0].message.content\n",
    "print(\"回答:\\n\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
